<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kafka on Peng ganyu blog</title>
    <link>https://xibolun.github.io/tags/kafka/</link>
    <description>Recent content in kafka on Peng ganyu blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 18 Sep 2019 14:37:41 +0800</lastBuildDate><atom:link href="https://xibolun.github.io/tags/kafka/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kafka(二)操作</title>
      <link>https://xibolun.github.io/post/kafka/kafka%E4%BA%8C%E6%93%8D%E4%BD%9C/</link>
      <pubDate>Wed, 18 Sep 2019 14:37:41 +0800</pubDate>
      
      <guid>https://xibolun.github.io/post/kafka/kafka%E4%BA%8C%E6%93%8D%E4%BD%9C/</guid>
      <description>Topic 创建；topic 拥有一个分区，一个备份 bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test 创建多个分区，多个备份 bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic zstack --partitions 2 --replication-factor 1 创建好的分区与备份体现在log里面 # ls</description>
    </item>
    
    <item>
      <title>Kafka(一)环境搭建及问题整理</title>
      <link>https://xibolun.github.io/post/kafka/kafka%E4%B8%80%E5%85%A5%E9%97%A8/</link>
      <pubDate>Tue, 30 Jul 2019 00:20:07 +0800</pubDate>
      
      <guid>https://xibolun.github.io/post/kafka/kafka%E4%B8%80%E5%85%A5%E9%97%A8/</guid>
      <description>环境搭建 集群 Topic:cloudboot PartitionCount:1 ReplicationFactor:3 Configs: Topic: cloudboot Partition: 0 Leader: 1 Replicas: 1,2,0 Isr: 1,2,0 问题 Kafka的消费流转模型是怎么样的？ 新连接上来的消费者的offset是怎么样的呢？难道将每一个p</description>
    </item>
    
  </channel>
</rss>
